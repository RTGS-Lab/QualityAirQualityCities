{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b91a7c3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Observed Air Quality (PurpleAir)\n",
    "\n",
    "This notebook retrieves readings from PurpleAir Sensors in Minneapolis and cleans the entries and saves the results as a csv file.\n",
    "\n",
    "Documentation is available here: https://api.purpleair.com.\n",
    "You can read this article for help getting started: https://community.purpleair.com/t/making-api-calls-with-the-purpleair-api/180.\n",
    "\n",
    "From PurpleAir: \n",
    "\n",
    "\"The data from individual sensors will update no less than every 30 seconds. As a courtesy, we ask that you limit the number of requests to no more than once every 1 to 10 minutes, assuming you are only using the API to obtain data from sensors. If retrieving data from multiple sensors at once, please send a single request rather than individual requests in succession.\n",
    "\n",
    "The PurpleAir historical API is released as of July 18, 2022. For more information, view this post: https://community.purpleair.com/t/new-version-of-the-purpleair-api-on-july-18th/1251.\n",
    "\n",
    "Please let us know if you have any questions or concerns, and have a great day!\"\n",
    "\n",
    "A paper on this process: https://doi.org/10.5194/amt-14-4617-2021 (Link for [Download](https://www.researchgate.net/publication/352663348_Development_and_application_of_a_United_States-wide_correction_for_PM25_data_collected_with_the_PurpleAir_sensor) )\n",
    "\n",
    "Chat on which PM Estimate to use: https://community.purpleair.com/t/pm2-5-algorithms/3972/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f319216",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Packages\n",
    "\n",
    "# File manipulation\n",
    "\n",
    "import os # For working with Operating System\n",
    "import requests # Accessing the Web\n",
    "import datetime as dt # Working with dates/times\n",
    "import io # Input/Output Bytes objects\n",
    "\n",
    "# Analysis\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacecd5a",
   "metadata": {},
   "source": [
    "## Set Working Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2d33a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get CWD\n",
    "\n",
    "# cwd = os.getcwd() # This is a global variable for where the notebook is (must change if running in arcpro)\n",
    "\n",
    "# # Create GeoDataBase\n",
    "# # This is the communal GeoDataBase\n",
    "\n",
    "# if not os.path.exists(os.path.join(cwd, '..', '..', 'data', 'QAQC.gdb')): # If it doesn't exist, create it\n",
    "\n",
    "#     arcpy.management.CreateFileGDB(os.path.join(cwd, '..', '..', 'data'), 'QAQC')\n",
    "\n",
    "# # Make it workspace\n",
    "\n",
    "# arcpy.env.workspace = os.path.join(cwd, '..', '..', 'data', 'QAQC.gdb')\n",
    "\n",
    "# arcpy.env.overwriteOutput = True # Overwrite layers is okay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc473325",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b73b4a0-daaf-4a02-b0e4-4a218f2afa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_threshold = 28 # Micgrograms per meter cubed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a91ea8-28a7-4408-a9bf-8ad6b386b231",
   "metadata": {},
   "source": [
    "### Summary Statistics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbe32cea-9e74-4cff-aa14-7427277fb63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n_observations', 'min', 'max']\n",
      "[<class 'int'>, <class 'float'>, <class 'float'>]\n",
      "[<function n_observations at 0x7f7c88dcda20>, <function getminmax at 0x7f7c88dcdcf0>]\n"
     ]
    }
   ],
   "source": [
    "%run Summary_Functions.py\n",
    "\n",
    "print(summary_stats_names)\n",
    "print(summary_stats_dtypes)\n",
    "print(summary_stats_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f861d3ec-7915-4a0e-9030-091f85551b8d",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9add3cf8-5631-4836-8729-84baaa29af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QAQC\n",
    "\n",
    "def qaqc(df):\n",
    "    '''This function will perform some basic QAQC\n",
    "    '''\n",
    "    \n",
    "    clean_df = df.copy()\n",
    "    \n",
    "    # Convert timestamp to datetime\n",
    "    \n",
    "    clean_df['timestamp'] = pd.to_datetime(clean_df['timestamp'], unit='s')\n",
    "    \n",
    "    # Remove obvious error values\n",
    "    \n",
    "    clean_df = clean_df[clean_df.pm25 < 1000] \n",
    "    \n",
    "    # Remove NaNs\n",
    "    \n",
    "    clean_df = clean_df.dropna()\n",
    "    \n",
    "    return clean_df\n",
    "\n",
    "# Remove and record Spikes\n",
    "\n",
    "def get_spikes(df, spike_threshold):\n",
    "    '''This function removes spikes from a dataframe \n",
    "    and returns both the new dataframe\n",
    "    and a separate spike dataframe\n",
    "    '''\n",
    "    \n",
    "    df_w_spikes = df.copy()\n",
    "    \n",
    "    condition = (df.pm25 > spike_threshold)\n",
    "    \n",
    "    df_w_spikes['is_spike'] = condition\n",
    "    \n",
    "    spikes = df[condition]\n",
    "    \n",
    "    return df_w_spikes, spikes\n",
    "\n",
    "# Get Summary Stats\n",
    "\n",
    "def get_summary_stats(df):\n",
    "    ''' This is the main function. It will run all of our functions that get summary stats\n",
    "    and return as a list.\n",
    "    '''\n",
    "    \n",
    "    stats = []\n",
    "    \n",
    "    # Run the functions\n",
    "    \n",
    "    for f in summary_stats_functions:\n",
    "        stats += f(df)\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ae2cb3",
   "metadata": {},
   "source": [
    "### Set Up Parameters for Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8dbe69f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your Purple Air api key A9B09E48-AEE2-11ED-B6F4-42010A800007\n"
     ]
    }
   ],
   "source": [
    "# This is my personal API key... Please use responsibly!\n",
    "\n",
    "api = input('Please enter your Purple Air api key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa2da2a8-3efa-401e-b204-6e99c3053199",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Query Strings\n",
    "\n",
    "# Average string (in minutes) 1440 is 1 day average\n",
    "\n",
    "avg_string = 'average=10'\n",
    "\n",
    "# Environmental fields\n",
    "\n",
    "env_fields = ['pm2.5_cf_1']\n",
    "\n",
    "env_fields_string = 'fields=' + '%2C%20'.join(env_fields)\n",
    "\n",
    "# My Header\n",
    "\n",
    "my_headers = {'X-API-Key': api}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f0d126",
   "metadata": {},
   "source": [
    "## The Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15516cf4-2085-48db-90ce-43a06fdb7c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Run on  2023-04-19 19:58:12.245160\n"
     ]
    }
   ],
   "source": [
    "## Iterables\n",
    "\n",
    "sensor_ids = [3088, 5582, 11134, 142718, 142720] # This should be an iterable of the sensor ids as integers\n",
    "\n",
    "datelist = pd.date_range(start = dt.datetime(2022,6,15), # June 15, 2022,\n",
    "                         end = dt.datetime.today(),\n",
    "                        normalize = True)\n",
    "\n",
    "print('Last Run on ', dt.datetime.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98951b98-370f-4be1-9f73-e45e6548df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize Storage\n",
    "\n",
    "# Daily Summary\n",
    "\n",
    "cols = ['date'] + ['sensor_index'] + summary_stats_names\n",
    "\n",
    "datatypes = [str, int] + summary_stats_dtypes\n",
    "\n",
    "dtypes = np.dtype(list(zip(cols, datatypes)))\n",
    "\n",
    "daily_summary_df = pd.DataFrame(np.empty(0, dtype = dtypes))\n",
    "\n",
    "# Spikes\n",
    "\n",
    "all_spikes_df = pd.DataFrame(np.empty(0, dtype = [('timestamp', pd._libs.tslibs.timestamps.Timestamp),\n",
    "                                              ('pm25', float),\n",
    "                                              ('sensor_index', int)]\n",
    "                                 )\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cdbba671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate through the days\n",
    "\n",
    "for i in range(len(datelist)-1):\n",
    "    \n",
    "    # Set up Timestamp for query    \n",
    "    \n",
    "    start_timestamp = int(datelist[i].timestamp())\n",
    "    end_timestamp = int(datelist[i+1].timestamp())\n",
    "    \n",
    "    time_string = 'start_timestamp=' + str(start_timestamp) + '&end_timestamp=' + str(end_timestamp)\n",
    "    \n",
    "    # Iterate through the Sensors\n",
    "    \n",
    "    for sensor_id in sensor_ids:\n",
    "        # Base URL\n",
    "        base_url = f'https://api.purpleair.com/v1/sensors/{sensor_id}/history/csv?'\n",
    "\n",
    "        # Put it all together\n",
    "        query_url = base_url + '&'.join([time_string, avg_string, env_fields_string])\n",
    "\n",
    "        response = requests.get(query_url, headers=my_headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "\n",
    "            # Read response as CSV data\n",
    "            csv_data = response.content.decode('utf-8')\n",
    "\n",
    "            if csv_data.count('\\n') == 1: # There is only one line (empty data)\n",
    "                print(f\"No data for sensor {sensor_id} on {datelist[i]}\")\n",
    "                \n",
    "            else:\n",
    "                # Parse CSV data into pandas DataFrame\n",
    "                df_individual_sensor = pd.read_csv(io.StringIO(csv_data),\n",
    "                                                   header=0\n",
    "                                                  )[['time_stamp', 'pm2.5_cf_1']]\n",
    "                \n",
    "                df_individual_sensor.columns = ['timestamp', 'pm25']\n",
    "                \n",
    "                # Perform QAQC\n",
    "                \n",
    "                clean = qaqc(df_individual_sensor)\n",
    "                \n",
    "                # Remove Spikes & Concatenate to main storage of spikes\n",
    "\n",
    "                clean_w_spikes, spikes = get_spikes(clean, spike_threshold)\n",
    "                \n",
    "                spikes['sensor_index'] = int(sensor_id)\n",
    "                \n",
    "                all_spikes_df = pd.concat([all_spikes_df, spikes], ignore_index=True)\n",
    "                \n",
    "                # Get Stats\n",
    "\n",
    "                sum_stats = get_summary_stats(clean_no_spikes)\n",
    "                \n",
    "                # Add to the daily summary dataframe\n",
    "                \n",
    "                row = [str(datelist[i].date()), int(sensor_id)] + sum_stats\n",
    "                \n",
    "                daily_summary_df.loc[len(daily_summary_df.index)] = row\n",
    "        else:\n",
    "            print(f\"Error fetching data for sensor {sensor_id}: {r.status_code} on {datelist[i]}\")\n",
    "            \n",
    "            \n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6678d3b-0846-416f-b0bd-f44b2f8dc0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sensor_index</th>\n",
       "      <th>n_observations</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>3088</td>\n",
       "      <td>144</td>\n",
       "      <td>0.396</td>\n",
       "      <td>5.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>3088</td>\n",
       "      <td>144</td>\n",
       "      <td>0.396</td>\n",
       "      <td>5.406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  sensor_index  n_observations    min    max\n",
       "0  2022-06-15          3088             144  0.396  5.406\n",
       "1  2022-06-15          3088             144  0.396  5.406"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20feb537-f129-4de3-889f-fcc1e1aa81a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pm25</th>\n",
       "      <th>sensor_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [timestamp, pm25, sensor_index]\n",
       "Index: []"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d5d3c46-9a9c-4516-95b0-fd94907330e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pm25</th>\n",
       "      <th>is_spike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-15 22:10:00</td>\n",
       "      <td>1.374</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-15 02:50:00</td>\n",
       "      <td>2.326</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-15 06:20:00</td>\n",
       "      <td>1.310</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-15 21:00:00</td>\n",
       "      <td>1.362</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-15 23:40:00</td>\n",
       "      <td>1.853</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2022-06-15 20:20:00</td>\n",
       "      <td>2.952</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2022-06-15 19:00:00</td>\n",
       "      <td>3.773</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2022-06-15 17:00:00</td>\n",
       "      <td>0.886</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2022-06-15 05:00:00</td>\n",
       "      <td>2.331</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2022-06-15 04:40:00</td>\n",
       "      <td>2.365</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp   pm25  is_spike\n",
       "0   2022-06-15 22:10:00  1.374     False\n",
       "1   2022-06-15 02:50:00  2.326     False\n",
       "2   2022-06-15 06:20:00  1.310     False\n",
       "3   2022-06-15 21:00:00  1.362     False\n",
       "4   2022-06-15 23:40:00  1.853     False\n",
       "..                  ...    ...       ...\n",
       "139 2022-06-15 20:20:00  2.952     False\n",
       "140 2022-06-15 19:00:00  3.773     False\n",
       "141 2022-06-15 17:00:00  0.886     False\n",
       "142 2022-06-15 05:00:00  2.331     False\n",
       "143 2022-06-15 04:40:00  2.365     False\n",
       "\n",
       "[144 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_w_spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "728fcb69-6c8d-4abb-ac6f-ebc3469481bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save a test dataframe\n",
    "\n",
    "# clean_w_spikes.to_csv('example_df.csv', index = False)\n",
    "\n",
    "# Save it!!!\n",
    "\n",
    "# daily_summary_df.to_csv('daily_summaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ad1fc-33b7-487c-97bb-476cae55eef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
