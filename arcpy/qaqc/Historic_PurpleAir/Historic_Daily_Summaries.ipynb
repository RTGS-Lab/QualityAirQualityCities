{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b91a7c3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Observed Air Quality (PurpleAir)\n",
    "\n",
    "This notebook retrieves readings from PurpleAir Sensors in Minneapolis and cleans the entries and saves the results as a csv file.\n",
    "\n",
    "Documentation is available here: https://api.purpleair.com.\n",
    "You can read this article for help getting started: https://community.purpleair.com/t/making-api-calls-with-the-purpleair-api/180.\n",
    "\n",
    "From PurpleAir: \n",
    "\n",
    "\"The data from individual sensors will update no less than every 30 seconds. As a courtesy, we ask that you limit the number of requests to no more than once every 1 to 10 minutes, assuming you are only using the API to obtain data from sensors. If retrieving data from multiple sensors at once, please send a single request rather than individual requests in succession.\n",
    "\n",
    "The PurpleAir historical API is released as of July 18, 2022. For more information, view this post: https://community.purpleair.com/t/new-version-of-the-purpleair-api-on-july-18th/1251.\n",
    "\n",
    "Please let us know if you have any questions or concerns, and have a great day!\"\n",
    "\n",
    "A paper on this process: https://doi.org/10.5194/amt-14-4617-2021 (Link for [Download](https://www.researchgate.net/publication/352663348_Development_and_application_of_a_United_States-wide_correction_for_PM25_data_collected_with_the_PurpleAir_sensor) )\n",
    "\n",
    "Chat on which PM Estimate to use: https://community.purpleair.com/t/pm2-5-algorithms/3972/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f319216",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Packages\n",
    "\n",
    "# File manipulation\n",
    "\n",
    "import os # For working with Operating System\n",
    "import requests # Accessing the Web\n",
    "import datetime as dt # Working with dates/times\n",
    "import io # Input/Output Bytes objects\n",
    "import time # For sleep in for loop\n",
    "\n",
    "# Analysis\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc473325",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b73b4a0-daaf-4a02-b0e4-4a218f2afa0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spike_threshold = 28 # Micgrograms per meter cubed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dbe69f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your Purple Air api key 51592903-B445-11ED-B6F4-42010A800007\n"
     ]
    }
   ],
   "source": [
    "# This is my personal API key... Please use responsibly!\n",
    "\n",
    "api = input('Please enter your Purple Air api key')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426aaea8-9c80-468b-a7a9-aa05faf955e6",
   "metadata": {},
   "source": [
    "### Sensor Indices and Start Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b736200-a5d7-4d1a-81a9-ab0cbc5681be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensor Indices (from City of Minneapolis)\n",
    "\n",
    "sensor_info = pd.read_excel('PA IDs and indexes.xlsx') # Load as DataFrame\n",
    "\n",
    "sensor_ids = sensor_info['Sensor Index'].dropna().astype(int) # This should be an iterable of the sensor ids as integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cab4e82-3b0e-42db-a404-5a3dc2b8fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSensorsData(query='', api_read_key=''):\n",
    "\n",
    "    # my_url is assigned the URL we are going to send our request to.\n",
    "    url = 'https://api.purpleair.com/v1/sensors?' + query\n",
    "    \n",
    "    # print('Here is the full url for the API call:\\n\\n', url)\n",
    "\n",
    "    # my_headers is assigned the context of our request we want to make. In this case\n",
    "    # we will pass through our API read key using the variable created above.\n",
    "    my_headers = {'X-API-Key':api_read_key}\n",
    "\n",
    "    # This line creates and sends the request and then assigns its response to the\n",
    "    # variable, r.\n",
    "    response = requests.get(url, headers=my_headers)\n",
    "\n",
    "    # We then return the response we received.\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e993408-c849-4109-a8a4-815ff8cbc2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get start Times\n",
    "\n",
    "sensor_string = '%2C'.join(sensor_ids.astype(str))\n",
    "\n",
    "query = 'fields=date_created&show_only=' + sensor_string\n",
    "\n",
    "response = getSensorsData(query, api)\n",
    "\n",
    "response_dict = response.json() # Read response as a json (dictionary)\n",
    "\n",
    "col_names = response_dict['fields']\n",
    "data = np.array(response_dict['data'])\n",
    "\n",
    "sensors_df = pd.DataFrame(data, columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b9ff880-b34a-4830-b71d-c66eeb8496c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_index</th>\n",
       "      <th>date_created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142718</td>\n",
       "      <td>1642013869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142720</td>\n",
       "      <td>1642013875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142726</td>\n",
       "      <td>1642013897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142724</td>\n",
       "      <td>1642013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142730</td>\n",
       "      <td>1642013916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sensor_index  date_created\n",
       "0        142718    1642013869\n",
       "1        142720    1642013875\n",
       "2        142726    1642013897\n",
       "3        142724    1642013889\n",
       "4        142730    1642013916"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensors_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a91ea8-28a7-4408-a9bf-8ad6b386b231",
   "metadata": {},
   "source": [
    "### Summary Statistics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbe32cea-9e74-4cff-aa14-7427277fb63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat Names:\n",
      "\n",
      " ['n_observations', 'pm25_fullDay_mean', 'pm25_fullDay_min', 'pm25_fullDay_minTime', 'pm25_fullDay_max', 'pm25_fullDay_maxTime', 'pm25_fullDay_std', 'pm25_fullDay_minutesAbove12ug', 'pm25_morningRush_mean', 'pm25_morningRush_min', 'pm25_morningRush_minTime', 'pm25_morningRush_max', 'pm25_morningRush_maxTime', 'pm25_morningRush_std', 'pm25_eveningRush_mean', 'pm25_eveningRush_min', 'pm25_eveningRush_minTime', 'pm25_eveningRush_max', 'pm25_eveningRush_maxTime', 'pm25_eveningRush_std', 'pm25_daytimeAmbient_mean', 'pm25_daytimeAmbient_min', 'pm25_daytimeAmbient_minTime', 'pm25_daytimeAmbient_max', 'pm25_daytimeAmbient_maxTime', 'pm25_daytimeAmbient_std', 'pm25_nighttimeAmbient_mean', 'pm25_nighttimeAmbient_min', 'pm25_nighttimeAmbient_minTime', 'pm25_nighttimeAmbient_max', 'pm25_nighttimeAmbient_maxTime', 'pm25_nighttimeAmbient_std'] \n",
      "\n",
      "Stat Types:\n",
      "\n",
      " [<class 'int'>, <class 'float'>, <class 'float'>, <class 'str'>, <class 'float'>, <class 'str'>, <class 'float'>, <class 'int'>, <class 'float'>, <class 'float'>, <class 'str'>, <class 'float'>, <class 'str'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'str'>, <class 'float'>, <class 'str'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'str'>, <class 'float'>, <class 'str'>, <class 'float'>, <class 'float'>, <class 'float'>, <class 'str'>, <class 'float'>, <class 'str'>, <class 'float'>] \n",
      "\n",
      "Function Names:\n",
      "\n",
      " [<function n_observations at 0x7f935665b520>, <function pm25_fullDay_stats at 0x7f935665b640>, <function daily_minutes_above_12ug at 0x7f935665b5b0>, <function pm25_morningRush_stats at 0x7f93560f93f0>, <function getEveningRushHourStats at 0x7f93560f9480>, <function pm25_daytimeAmbient_stats at 0x7f93560f9510>, <function nighttime_ambient at 0x7f93560f95a0>]\n"
     ]
    }
   ],
   "source": [
    "%run Summary_Functions.py\n",
    "\n",
    "print('Stat Names:\\n\\n', summary_stats_names, '\\n')\n",
    "print('Stat Types:\\n\\n',summary_stats_dtypes, '\\n')\n",
    "\n",
    "print('Function Names:\\n\\n', summary_stats_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f861d3ec-7915-4a0e-9030-091f85551b8d",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9add3cf8-5631-4836-8729-84baaa29af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QAQC\n",
    "\n",
    "def qaqc(df):\n",
    "    '''This function wil perform some basic QAQC\n",
    "    '''\n",
    "    \n",
    "    clean_df = df.copy()\n",
    "    \n",
    "    # Convert timestamp to datetime\n",
    "    \n",
    "    clean_df['timestamp'] = pd.to_datetime(clean_df['timestamp'], unit='s')\n",
    "    \n",
    "    # Remove obvious error values\n",
    "    \n",
    "    clean_df = clean_df[clean_df.pm25 < 1000] \n",
    "    \n",
    "    # Remove NaNs\n",
    "    \n",
    "    clean_df = clean_df.dropna()\n",
    "    \n",
    "    return clean_df\n",
    "\n",
    "# Remove and record Spikes\n",
    "\n",
    "def get_spikes(df, spike_threshold):\n",
    "    '''This function removes spikes from a dataframe \n",
    "    and returns both the new dataframe\n",
    "    and a separate spike dataframe\n",
    "    '''\n",
    "    \n",
    "    df_w_spikes = df.copy()\n",
    "    \n",
    "    condition = (df.pm25 > spike_threshold)\n",
    "    \n",
    "    df_w_spikes['is_spike'] = condition\n",
    "    \n",
    "    spikes = df_w_spikes[condition]\n",
    "    \n",
    "    return df_w_spikes, spikes\n",
    "\n",
    "# Get Summary Stats\n",
    "\n",
    "def get_summary_stats(df):\n",
    "    ''' This is the main function. It will run all of our functions that get summary stats\n",
    "    and return as a list.\n",
    "    '''\n",
    "    \n",
    "    stats = []\n",
    "    \n",
    "    # Run the functions\n",
    "    \n",
    "    for f in summary_stats_functions:\n",
    "        stats += f(df)\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ae2cb3",
   "metadata": {},
   "source": [
    "### Set Up Parameters for Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa2da2a8-3efa-401e-b204-6e99c3053199",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Query Strings\n",
    "\n",
    "# Average string (in minutes) 1440 is 1 day average\n",
    "\n",
    "avg_string = 'average=10'\n",
    "\n",
    "# Environmental fields\n",
    "\n",
    "env_fields = ['pm2.5_cf_1']\n",
    "\n",
    "env_fields_string = 'fields=' + '%2C%20'.join(env_fields)\n",
    "\n",
    "# My Header\n",
    "\n",
    "my_headers = {'X-API-Key': api}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f0d126",
   "metadata": {},
   "source": [
    "## The Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15516cf4-2085-48db-90ce-43a06fdb7c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Run on  2023-04-20 13:28:32.143514\n"
     ]
    }
   ],
   "source": [
    "## Iterables\n",
    "\n",
    "# Dates\n",
    "\n",
    "# first_date = pd.to_datetime(sensors_df.date_created, unit = 's').min() # This is just untrue...\n",
    "\n",
    "first_date = dt.datetime(2022, 6, 15) # June 15th, 2022?\n",
    "\n",
    "datelist = pd.date_range(start = first_date, \n",
    "                         end = dt.datetime.today(),\n",
    "                        normalize = True)\n",
    "\n",
    "print('Last Run on ', dt.datetime.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98951b98-370f-4be1-9f73-e45e6548df2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize Storage\n",
    "\n",
    "# Daily Summary\n",
    "\n",
    "cols = ['date'] + ['sensor_index'] + summary_stats_names\n",
    "\n",
    "datatypes = [str, int] + summary_stats_dtypes\n",
    "\n",
    "dtypes = np.dtype(list(zip(cols, datatypes)))\n",
    "\n",
    "daily_summary_df = pd.DataFrame(np.empty(0, dtype = dtypes))\n",
    "\n",
    "# Daily Summary (No Spikes)\n",
    "\n",
    "cols = ['date'] + ['sensor_index'] + summary_stats_names\n",
    "\n",
    "datatypes = [str, int] + summary_stats_dtypes\n",
    "\n",
    "dtypes = np.dtype(list(zip(cols, datatypes)))\n",
    "\n",
    "daily_summary_no_spikes_df = pd.DataFrame(np.empty(0, dtype = dtypes))\n",
    "\n",
    "# Spikes\n",
    "\n",
    "all_spikes_df = pd.DataFrame(np.empty(0, dtype = [('timestamp', pd._libs.tslibs.timestamps.Timestamp),\n",
    "                                              ('pm25', float),\n",
    "                                              ('sensor_index', int)]\n",
    "                                 )\n",
    "                        )\n",
    "\n",
    "# No Data for sensor\n",
    "\n",
    "no_data = pd.DataFrame(np.empty(0, dtype = [('date', str),\n",
    "                                            ('sensor_index', int)\n",
    "                                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbba671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate through the days\n",
    "\n",
    "for i in range(len(datelist)-1): \n",
    "    \n",
    "    # Set up Timestamp for query    \n",
    "    \n",
    "    start_timestamp = int(datelist[i].timestamp())\n",
    "    end_timestamp = int(datelist[i+1].timestamp())\n",
    "    \n",
    "    time_string = 'start_timestamp=' + str(start_timestamp) + '&end_timestamp=' + str(end_timestamp)\n",
    "    \n",
    "    # Select Sensors that had been created before this date\n",
    "    \n",
    "    select_sensors = sensors_df[sensors_df.date_created <= start_timestamp]\n",
    "    \n",
    "    sensor_ids = select_sensors.sensor_index\n",
    "    \n",
    "    # Iterate through the Sensors\n",
    "    \n",
    "    for sensor_id in sensor_ids:\n",
    "        \n",
    "        time.sleep(3)\n",
    "\n",
    "        # Base URL\n",
    "        base_url = f'https://api.purpleair.com/v1/sensors/{sensor_id}/history/csv?'\n",
    "\n",
    "        # Put it all together\n",
    "        query_url = base_url + '&'.join([time_string, avg_string, env_fields_string])\n",
    "\n",
    "        response = requests.get(query_url, headers=my_headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "\n",
    "            # Read response as CSV data\n",
    "            csv_data = response.content.decode('utf-8')\n",
    "\n",
    "            if csv_data.count('\\n') == 1: # There is only one line (empty data)\n",
    "                # print(f\"No data for sensor {sensor_id} on {datelist[i]}\")\n",
    "                \n",
    "                no_data.loc[len(no_data.index)] = [datelist[i], sensor_id]\n",
    "                \n",
    "            else:\n",
    "                # Parse CSV data into pandas DataFrame\n",
    "                df_individual_sensor = pd.read_csv(io.StringIO(csv_data),\n",
    "                                                   header=0\n",
    "                                                  )[['time_stamp', 'pm2.5_cf_1']]\n",
    "                \n",
    "                df_individual_sensor.columns = ['timestamp', 'pm25']\n",
    "                \n",
    "                # Perform QAQC\n",
    "                \n",
    "                clean = qaqc(df_individual_sensor)\n",
    "                \n",
    "                # Remove Spikes & Concatenate to main storage of spikes\n",
    "\n",
    "                clean_w_spikes, spikes = get_spikes(clean, spike_threshold)\n",
    "                \n",
    "                spikes['sensor_index'] = int(sensor_id)\n",
    "                \n",
    "                all_spikes_df = pd.concat([all_spikes_df, spikes], ignore_index=True)\n",
    "                \n",
    "                # Get Stats (With Spikes)\n",
    "\n",
    "                sum_stats = get_summary_stats(clean_w_spikes)\n",
    "                \n",
    "                # Add to the daily summary dataframe\n",
    "                \n",
    "                row = [str(datelist[i].date()), int(sensor_id)] + sum_stats\n",
    "                \n",
    "                daily_summary_df.loc[len(daily_summary_df.index)] = row\n",
    "                \n",
    "                # Get Stats (Without Spikes)\n",
    "                \n",
    "                no_spikes = clean_w_spikes[clean_w_spikes.is_spike == False]\n",
    "                \n",
    "                sum_stats = get_summary_stats(no_spikes)\n",
    "                \n",
    "                # Add to the daily summary dataframe\n",
    "                \n",
    "                row = [str(datelist[i].date()), int(sensor_id)] + sum_stats\n",
    "                \n",
    "                daily_summary_no_spikes_df.loc[len(daily_summary_no_spikes_df.index)] = row\n",
    " \n",
    "        else:\n",
    "            print(f\"Error fetching data for sensor {sensor_id}: {response.status_code} on {datelist[i]}\")\n",
    "            \n",
    "            \n",
    "    # if i == 7:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6678d3b-0846-416f-b0bd-f44b2f8dc0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc3f57f-8f38-4f5f-b003-4be0b9991c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_summary_no_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20feb537-f129-4de3-889f-fcc1e1aa81a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea14eda7-eba3-470c-87d9-755dc50d8da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d044a94d-b871-41b4-87a7-a153d04315a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_summary_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "728fcb69-6c8d-4abb-ac6f-ebc3469481bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save a test dataframe\n",
    "\n",
    "# clean_w_spikes.to_csv('example_df.csv', index = False)\n",
    "\n",
    "# Save it!?!\n",
    "\n",
    "# daily_summary_df.to_csv('daily_summaries.csv')\n",
    "\n",
    "# daily_summary_no_spikes_df.to_csv('daily_summaries_no_spikes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ad1fc-33b7-487c-97bb-476cae55eef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
